# Workspace Project Overview

This document provides a brief overview of other projects found in the `/Users/mdwong001/Desktop/code/rag/` directory, based on their README files. Please note that for brevity, only the initial parts of the READMEs are included here.

---

## Project: mem0

**README Summary (First 100 lines approx.):**
```
<p align="center">
  <a href="https://github.com/mem0ai/mem0">
    <img src="docs/images/banner-sm.png" width="800px" alt="Mem0 - The Memory Layer for Personalized AI">
  </a>
</p>
<p align="center" style="display: flex; justify-content: center; gap: 20px; align-items: center;">
  <a href="https://trendshift.io/repositories/11194" target="blank">
    <img src="https://trendshift.io/api/badge/repositories/11194" alt="mem0ai%2Fmem0 | Trendshift" width="250" height="55"/>
  </a>
</p>

<p align="center">
  <a href="https://mem0.ai">Learn more</a>
  ·
  <a href="https://mem0.dev/DiG">Join Discord</a>
  ·
  <a href="https://mem0.dev/demo">Demo</a>
</p>

<p align="center">
  <a href="https://mem0.dev/DiG">
    <img src="https://dcbadge.vercel.app/api/server/6PzXDgEjG5?style=flat" alt="Mem0 Discord">
  </a>
  <a href="https://pepy.tech/project/mem0ai">
    <img src="https://img.shields.io/pypi/dm/mem0ai" alt="Mem0 PyPI - Downloads">
  </a>
  <a href="https://github.com/mem0ai/mem0">
    <img src="https://img.shields.io/github/commit-activity/m/mem0ai/mem0?style=flat-square" alt="GitHub commit activity">
  </a>
  <a href="https://pypi.org/project/mem0ai" target="blank">
    <img src="https://img.shields.io/pypi/v/mem0ai?color=%2334D058&label=pypi%20package" alt="Package version">
  </a>
  <a href="https://www.npmjs.com/package/mem0ai" target="blank">
    <img src="https://img.shields.io/npm/v/mem0ai" alt="Npm package">
  </a>
  <a href="https://www.ycombinator.com/companies/mem0">
    <img src="https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square" alt="Y Combinator S24">
  </a>
</p>

<p align="center">
  <a href="https://mem0.ai/research"><strong>📄 Building Production-Ready AI Agents with Scalable Long-Term Memory →</strong></a>
</p>
<p align="center">
  <strong>⚡ +26% Accuracy vs. OpenAI Memory • 🚀 91% Faster • 💰 90% Fewer Tokens</strong>
</p>

##  🔥 Research Highlights
- **+26% Accuracy** over OpenAI Memory on the LOCOMO benchmark
- **91% Faster Responses** than full-context, ensuring low-latency at scale
- **90% Lower Token Usage** than full-context, cutting costs without compromise
- [Read the full paper](https://mem0.ai/research)

# Introduction

[Mem0](https://mem0.ai) ("mem-zero") enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. It remembers user preferences, adapts to individual needs, and continuously learns over time—ideal for customer support chatbots, AI assistants, and autonomous systems.

### Key Features & Use Cases

**Core Capabilities:**
- **Multi-Level Memory**: Seamlessly retains User, Session, and Agent state with adaptive personalization
- **Developer-Friendly**: Intuitive API, cross-platform SDKs, and a fully managed service option

**Applications:**
- **AI Assistants**: Consistent, context-rich conversations
- **Customer Support**: Recall past tickets and user history for tailored help
- **Healthcare**: Track patient preferences and history for personalized care
- **Productivity & Gaming**: Adaptive workflows and environments based on user behavior

## 🚀 Quickstart Guide <a name="quickstart"></a>

Choose between our hosted platform or self-hosted package:

### Hosted Platform

Get up and running in minutes with automatic updates, analytics, and enterprise security.

1. Sign up on [Mem0 Platform](https://app.mem0.ai)
2. Embed the memory layer via SDK or API keys

### Self-Hosted (Open Source)

Install the sdk via pip:

```bash
pip install mem0ai
```
...
```

---

## Project: agents-course

**README Summary (First 100 lines approx.):**
```
# <a href="https://hf.co/learn/agents-course" target="_blank">The Hugging Face Agents Course</a>

If you like the course, **don't hesitate to ⭐ star this repository**. This helps us to **make the course more visible 🤗**.

<img src="https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/please_star.gif" alt="Star the repo" />

## Content

The course is divided into 4 units. These will take you from **the basics of agents to a final assignment with a benchmark**.

Sign up here (it's free) 👉 <a href="https://bit.ly/hf-learn-agents" target="_blank">https://bit.ly/hf-learn-agents</a>

You can access the course here 👉 <a href="https://hf.co/learn/agents-course" target="_blank">https://hf.co/learn/agents-course</a>

| Unit    | Topic                                                                                                          | Description                                                                                                                            |
|---------|----------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|
| 0       | [Welcome to the Course](https://huggingface.co/learn/agents-course/en/unit0/introduction)                      | Welcome, guidelines, necessary tools, and course overview.                                                                             |
| 1       | [Introduction to Agents](https://huggingface.co/learn/agents-course/en/unit1/introduction)                     | Definition of agents, LLMs, model family tree, and special tokens.                                                                     |
| 1 Bonus | [Fine-tuning an LLM for Function-calling](https://huggingface.co/learn/agents-course/bonus-unit1/introduction) | Learn how to fine-tune an LLM for Function-Calling                                                                                     |
| 2       | [Frameworks for AI Agents](https://huggingface.co/learn/agents-course/unit2/introduction)                      | Overview of `smolagents`, `LangGraph` and `LlamaIndex`.                                                                                |
| 2.1     | [The Smolagents Framework](https://huggingface.co/learn/agents-course/unit2/smolagents/introduction)           | Learn how to build effective agents using the `smolagents` library, a lightweight framework for creating capable AI agents.            |
| 2.2     | [The LlamaIndex Framework](https://huggingface.co/learn/agents-course/unit2/llama-index/introduction)          | Learn how to build LLM-powered agents over your data using indexes and workflows using the `LlamaIndex` toolkit.                       |
| 2.3     | [The LangGraph Framework](https://huggingface.co/learn/agents-course/unit2/langgraph/introduction)             | Learn how to build production-ready applications using the `LangGraph` framework giving you control tools over the flow of your agent. |
| 2 Bonus | [Observability and Evaluation](https://huggingface.co/learn/agents-course/bonus-unit2/introduction)            | Learn how to trace and evaluate your agents.                                                                                           |
| 3       | [Use Case for Agentic RAG](https://huggingface.co/learn/agents-course/unit3/agentic-rag/introduction)          | Learn how to use Agentic RAG to help agents respond to different use cases using various frameworks.                                                                   |
| 4       | [Final Project - Create, Test and Certify Your Agent](https://huggingface.co/learn/agents-course/unit4/introduction)          | Automated evaluation of agents and leaderboard with student results.                                                                   |

## Prerequisites

- Basic knowledge of Python
- Basic knowledge of LLMs

## Contribution Guidelines

If you want to contribute to this course, you're welcome to do so. Feel free to open an issue or join the discussion in the [Discord](https://discord.gg/UrrTSsSyjb). For specific contributions, here are some guidelines:

### Small typo and grammar fixes

If you find a small typo or grammar mistake, please fix it yourself and submit a pull request. This is very helpful for students.

### New unit

If you want to add a new unit, **please create an issue in the repository, describe the unit, and why it should be added**. We will discuss it and if it's a good addition, we can collaborate on it.

## Citing the project

To cite this repository in publications:

```bibtex
@misc{agents-course,
  author = {Burtenshaw, Ben and Thomas, Joffrey and Simonini, Thomas and Paniego, Sergio},
  title = {The Hugging Face Agents Course},
  year = {2025},
  howpublished = {\url{https://github.com/huggingface/agents-course}},
  note = {GitHub repository},
}
```
...
```

---

## Project: my_rag1

**README Summary (First 100 lines approx.):**
```
# RAG 聊天机器人

这是一个基于检索增强生成（Retrieval Augmented Generation, RAG）的聊天机器人，使用LangGraph构建工作流，能够根据知识库中的文档内容回答用户问题。

## 项目结构

```
my_rag1/
├── data/                # 存放知识库文档和向量数据库
├── rag/                 # RAG核心模块
│   ├── __init__.py
│   ├── document_loader.py   # 文档加载和处理
│   ├── web_loader.py        # 网页加载和处理
│   ├── embeddings.py        # 向量嵌入模块
│   ├── retriever.py         # 检索模块
│   ├── llm.py              # 大语言模型接口
│   └── rag_graph.py        # LangGraph工作流定义
├── api/                 # API接口
│   ├── __init__.py
│   └── main.py          # FastAPI接口
├── utils/               # 工具函数
│   ├── __init__.py
│   ├── helpers.py       # 辅助函数
│   └── web_utils.py     # 网页处理工具
├── requirements.txt     # 项目依赖
├── env.example          # 环境变量示例
├── app.py               # 应用入口
└── ingest.py            # 文档导入脚本
```

## 基本架构

本项目采用基于LangGraph的RAG工作流，主要包括以下组件：

1. **文档加载器**：负责加载和处理各种格式的文档（PDF、TXT等）和网页内容
2. **向量存储**：使用ChromaDB存储文档的向量表示
3. **检索器**：根据用户查询检索相关文档片段
4. **LLM**：使用大语言模型（如OpenAI的GPT模型）生成回答
5. **LangGraph工作流**：定义RAG处理流程，包括查询分析、文档检索和回答生成等节点

## 工作流程

1. 用户提交问题
2. 系统分析问题，确定所需信息
3. 从向量数据库检索相关文档
4. 将检索到的文档与原始问题一起发送给LLM
5. LLM生成答案并返回给用户

## 详细架构与模块协作

### 整体架构

项目采用模块化设计，主要分为四个核心层：

1. **文档处理与索引层**：处理和向量化文档
2. **检索层**：根据用户查询检索相关内容
3. **生成层**：结合检索内容生成回答
4. **接口层**：与用户交互的界面

技术栈：
- LangChain：文档处理组件和向量存储接口
- LangGraph：RAG工作流定义和管理
- ChromaDB：向量数据库
- OpenAI/Anthropic API：提供生成模型和嵌入模型
- FastAPI：REST API服务

### 完整工作流程

系统工作流程分为两个主要阶段：

#### 文档索引阶段（离线）
1. 通过`ingest.py`加载文档（支持PDF、TXT、MD等格式）或网页内容
2. 使用`DocumentLoader`将文档或网页内容分割成小片段
3. 通过`embeddings`模块将文档转换为向量表示
4. 存储到ChromaDB向量数据库

#### 查询-回答阶段（在线）
1. 接收用户问题（通过命令行或API）
2. 查询分析：由`rag_graph.py`中的`_query_analysis_node`处理
3. 文档检索：由`_retrieval_node`从向量数据库中检索相关文档
4. 答案生成：由`_generation_node`结合检索内容和原始问题生成回答
5. 返回答案给用户

### 各模块功能与协作

#### rag模块（核心功能）
- **document_loader.py**：加载和分块本地文档
- **web_loader.py**：加载和处理网页内容
- **embeddings.py**：提供向量嵌入功能
- **retriever.py**：实现向量检索和管理
- **llm.py**：与大语言模型交互
- **rag_graph.py**：定义LangGraph工作流

#### utils模块（工具函数）
- **helpers.py**：提供环境变量加载、目录管理等辅助功能
- **web_utils.py**：提供网页抓取和处理功能

#### api模块（接口服务）
- **main.py**：提供REST API接口，接收查询并返回结果

#### 应用入口
- **app.py**：命令行应用入口，支持聊天模式、单次查询和服务器模式
- **ingest.py**：文档处理和索引入口

### 模块间数据流

1. **文档处理流**：
   ```
   DocumentLoader加载文档/WebLoader加载网页 → 文本分块 → 向量嵌入 → 存储到ChromaDB
   ```

2. **查询处理流**：
   ```
   用户输入 → RagGraph.invoke → 查询分析节点 → 检索节点 → 生成节点 → 返回答案
   ```

3. **接口协作**：
   - 命令行界面：通过`app.py`调用RAG组件
   - API服务：通过`api/main.py`提供HTTP接口
   - 两者都最终调用相同的核心RAG组件

核心工作流在`rag_graph.py`的`RagGraph`类中定义，使用LangGraph的状态图实现，将查询分析、文档检索和答案生成作为节点连接起来，形成完整的处理流程。整个系统通过明确的状态传递和数据流动，实现了一个完整的基于检索增强的生成系统。
...
```

---

## Project: e2e

**README Summary:**
No top-level README.md found for this project. It appears to be a collection of End-to-End example notebooks.

---

## Project: openai-cookbook

**README Summary (First 100 lines approx.):**
```
<a href="https://cookbook.openai.com" target="_blank">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="/images/openai-cookbook-white.png" style="max-width: 100%; width: 400px; margin-bottom: 20px">
    <img alt="OpenAI Cookbook Logo" src="/images/openai-cookbook.png" width="400px">
  </picture>
</a>

<h3></h3>
 
> ✨ Navigate at [cookbook.openai.com](https://cookbook.openai.com)

Example code and guides for accomplishing common tasks with the [OpenAI API](https://platform.openai.com/docs/introduction). To run these examples, you'll need an OpenAI account and associated API key ([create a free account here](https://beta.openai.com/signup)). Set an environment variable called `OPENAI_API_KEY` with your API key. Alternatively, in most IDEs such as Visual Studio Code, you can create an `.env` file at the root of your repo containing `OPENAI_API_KEY=<your API key>`, which will be picked up by the notebooks.

Most code examples are written in Python, though the concepts can be applied in any language.

For other useful tools, guides and courses, check out these [related resources from around the web](https://cookbook.openai.com/related_resources).

## License

MIT
```

---

## Project: ottomator-agents

**README Summary (First 100 lines approx.):**
```
# What is the Live Agent Studio?

The [Live Agent Studio](https://studio.ottomator.ai) is a community-driven platform developed by [oTTomator](https://ottomator.ai) for you to explore cutting-edge AI agents and learn how to implement them for yourself or your business! All agents on this platform are open source and, over time, will cover a very large variety of use cases.

The goal with the studio is to build an educational platform for you to learn how to do incredible things with AI, while still providing practical value so that you'll want to use the agents just for the sake of what they can do for you!

This platform is still in beta – expect longer response times under load, a rapidly growing agent library over the coming months, and a lot more content on this platform soon on Cole Medin's YouTube channel!

# What is this Repository for?

This repository contains the source code/workflow JSON for all the agents on the Live Agent Studio! Every agent being added to the platform is currently be open sourced here so we can not only create a curated collection of cutting-edge agents together as a community, but also learn from one another!

## Tokens

Most agents on the Live Agent Studio cost tokens to use, which are purchasable on the platform. However, when you first sign in you are given some tokens to start so you can use the agents free of charge! The biggest reason agents cost tokens is that we pay for the LLM usage since we host all the agents developed by you and the rest of the community!

[Purchase Tokens](https://studio.ottomator.ai/pricing)

## Future Plans

As the Live Agent Studio develops, it will become the go-to place to stay on top of what is possible with AI agents! Anytime there is a new AI technology, groundbreaking agent research, or a new tool/library to build agents with, it'll be featured through agents on the platform. It's a tall order, but we have big plans for the oTTomator community, and we're confident we can grow to accomplish this!

## FAQ

### I want to build an agent to showcase in the Live Agent Studio! How do I do that?

Head on over here to learn how to build an agent for the platform:

[Developer Guide](https://studio.ottomator.ai/guide)

Also check out [the sample n8n agent](~sample-n8n-agent~) for a starting point of building an n8n agent for the Live Agent Studio, and [the sample Python agent](~sample-python-agent~) for Python.

### How many tokens does it cost to use an agent?

Each agent will charge tokens per prompt. The number of tokens depends on the agent, as some agents use larger LLMs, some call LLMs multiple times, and some use paid APIs.

### Where can I go to talk about all these agents and get help implementing them myself?

Head on over to our Think Tank community and feel free to make a post!

[Think Tank Community](https://thinktank.ottomator.ai)

---

&copy; 2024 Live Agent Studio. All rights reserved.  
Created by oTTomator
```

---

## Project: kotaemon

**README Summary:**
No top-level README.md found for this project.

---

## Project: Lang_rag (Notebooks)

**README Summary:**
No top-level README.md found for this directory. It appears to contain LangGraph example notebooks such as `langgraph_self_rag_local.ipynb` and `langgraph_adaptive_rag.ipynb`.

--- 